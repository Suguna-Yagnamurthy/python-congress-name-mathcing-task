{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCBxSs8fMixItAZVP4Vi15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suguna-Yagnamurthy/python-congress-name-mathcing-task/blob/main/Suguna_Yagnamurthy_python_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbdLO_CrwSs1",
        "outputId": "a4cad5cc-e576-416e-a506-ce3353d2af98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'python-name-matching'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 47 (delta 9), reused 40 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (47/47), 492.16 KiB | 7.03 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/python-name-matching\n",
            "total 20\n",
            "drwxr-xr-x 4 root root 4096 Oct  6 09:03 .\n",
            "drwxr-xr-x 1 root root 4096 Oct  6 09:03 ..\n",
            "drwxr-xr-x 2 root root 4096 Oct  6 09:03 data\n",
            "drwxr-xr-x 8 root root 4096 Oct  6 09:03 .git\n",
            "-rw-r--r-- 1 root root 2526 Oct  6 09:03 README.md\n"
          ]
        }
      ],
      "source": [
        "#cloning and using the data set from github\n",
        "!git clone https://github.com/kiss-oliver/python-name-matching.git\n",
        "%cd python-name-matching\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile name_matcher.py\n",
        "#importing different modules used in this task\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import pandas as pnd\n",
        "import difflib #Fuzzy search\n",
        "FUZZY_SCORE_THRESHOLD = 90 #high threshold for a tighter match and minimising false matches\n",
        "\n",
        "#Creating a safe string output instead of Nan/None\n",
        "def safe_str(x):\n",
        "    if pnd.isna(x):\n",
        "        return \"\"\n",
        "    return str(x)\n",
        "\n",
        "#not processing empty values\n",
        "def normalize_name(raw):\n",
        "    simp = safe_str(raw).strip()\n",
        "    if simp == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize spaces and keep commas to differentiate names as first and last\n",
        "    simp = simp.replace(\"\\u00A0\", \" \")\n",
        "    simp = re.sub(r\"\\s+\", \" \", simp).strip()\n",
        "\n",
        "    # Flip \"Last name, First name\" if a comma exists\n",
        "    if \",\" in simp:\n",
        "        parts = [p.strip() for p in simp.split(\",\")]\n",
        "        if len(parts) >= 2:\n",
        "            last = parts[0]\n",
        "            rest = \" \".join(parts[1:])\n",
        "            simp = (rest + \" \" + last).strip()\n",
        "        else:\n",
        "            simp = simp.replace(\",\", \" \")\n",
        "\n",
        "    # Remove simple punctuation\n",
        "    simp = simp.replace(\".\", \" \")\n",
        "    simp = simp.replace(\"-\", \" \")\n",
        "    simp = simp.replace(\"'\", \"\")\n",
        "    simp = re.sub(r\"[^\\w\\s]\", \" \", simp)\n",
        "    simp = re.sub(r\"\\s+\", \" \", simp).strip()\n",
        "\n",
        "\n",
        "    # Tokenize and drop common suffixes\n",
        "    suffixes = {\"jr\", \"sr\", \"ii\", \"iii\", \"iv\", \"v\"}\n",
        "    tokens = [tok.lower() for tok in simp.split(\" \") if tok.strip() != \"\"]\n",
        "    tokens_wo_suffix = [tok for tok in tokens if tok not in suffixes]\n",
        "    return \" \".join(tokens_wo_suffix)\n",
        "\n",
        "#removing middle names and if only one work(token) then (token,token)\n",
        "def first_last(norm):\n",
        "    if norm == \"\":\n",
        "        return \"\", \"\"\n",
        "    parts = norm.split()\n",
        "    if len(parts) == 1:\n",
        "        return parts[0], parts[0]\n",
        "    return parts[0], parts[-1]\n",
        "\n",
        "#comparing the names and sorting alphabetically\n",
        "def token_sort_similarity(a, b):\n",
        "    tok_a = \" \".join(sorted(a.split()))\n",
        "    tok_b = \" \".join(sorted(b.split()))\n",
        "    res = difflib.SequenceMatcher(None, tok_a, tok_b).ratio()\n",
        "    return int(round(res * 100))\n",
        "\n",
        "#fuzzy similarity value between 0 to 100\n",
        "def simple_ratio(a, b):\n",
        "    res = difflib.SequenceMatcher(None, a, b).ratio()\n",
        "    return int(round(res * 100))\n",
        "\n",
        "#chosing best match\n",
        "def best_similarity(a, b):\n",
        "    return max(simple_ratio(a, b), token_sort_similarity(a, b))\n",
        "\n",
        "#finding name,combining first and last name and avoiding non-name strings\n",
        "def detect_name_from_row(row):\n",
        "    # Finding if the CSV have a column for the names\n",
        "    for col in row.index:\n",
        "        cl = str(col).lower()\n",
        "        if \"name\" in cl:\n",
        "            val = safe_str(row[col]).strip()\n",
        "            if val != \"\":\n",
        "                return val\n",
        "\n",
        "    # Handling the columns for last name whcih can be named in different ways.\n",
        "    first_candidates = {\"first_name\", \"name\"}\n",
        "    last_candidates  = {\"last_name\"}\n",
        "    fval, lval = \"\", \"\"\n",
        "    for col in row.index:\n",
        "        cl = str(col).lower()\n",
        "        val = safe_str(row[col]).strip()\n",
        "        if cl in first_candidates and val != \"\":\n",
        "            fval = val\n",
        "        if cl in last_candidates and val != \"\":\n",
        "            lval = val\n",
        "    if fval != \"\" and lval != \"\":\n",
        "        return (fval + \" \" + lval).strip()\n",
        "\n",
        "    # Fallback if values does not look like a name or if empty.\n",
        "    for col in row.index:\n",
        "        val = safe_str(row[col]).strip()\n",
        "        if val != \"\" and (\" \" in val) and (len(val.split()) <= 5):\n",
        "            return val\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "#function that reads the primary file i.e. Congress members\n",
        "def read_primary(primary_path):\n",
        "    if not os.path.isfile(primary_path):\n",
        "        raise FileNotFoundError(\"Primary dataset not found: \" + primary_path)\n",
        "    df = pnd.read_csv(primary_path, dtype=str, keep_default_na=False)\n",
        "    if df.shape[0] == 0:\n",
        "        raise ValueError(\"Primary dataset is empty: \" + primary_path)\n",
        "    return df\n",
        "\n",
        "def read_elections(data_dir):\n",
        "    \"\"\"\n",
        "    Read all 'congressional_elections_*.csv' files.\n",
        "    Skip empty/malformed files. Return list of candidates:\n",
        "      {name_raw, name_norm, year, file}\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    files = sorted(glob.glob(os.path.join(data_dir, \"congressional_elections_*.csv\")))\n",
        "    for path in files:\n",
        "        base = os.path.basename(path)\n",
        "        # Extract year if present\n",
        "        m = re.search(r\"(\\d{4})\", base)\n",
        "        year = m.group(1) if m else \"\"\n",
        "\n",
        "        #Check and skip empty files\n",
        "        try:\n",
        "            if os.path.getsize(path) == 0:\n",
        "                continue\n",
        "            df = pnd.read_csv(path, dtype=str, keep_default_na=False)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        #Skip empty CSV files\n",
        "        if df.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        #For each row normalize name , and save it with its year+file.\n",
        "        for _, row in df.iterrows():\n",
        "            raw = detect_name_from_row(row)\n",
        "            if raw.strip() == \"\":\n",
        "                continue\n",
        "            norm = normalize_name(raw)\n",
        "            if norm == \"\":\n",
        "                continue\n",
        "            out.append({\"name_raw\": raw, \"name_norm\": norm, \"year\": year, \"file\": base})\n",
        "    return out\n",
        "\n",
        "def build_indexes(candidates):\n",
        "    \"\"\"\n",
        "    Build:\n",
        "      - exact_set: all normalized names for quick exact lookups\n",
        "      - by_last: {last_name -> list of candidate dicts}\n",
        "    \"\"\"\n",
        "    exact_set = set()\n",
        "    by_last = {}\n",
        "    for cds in candidates:\n",
        "        norm = cds[\"name_norm\"]\n",
        "        exact_set.add(norm)\n",
        "        _, last = first_last(norm)\n",
        "        if last not in by_last:\n",
        "            by_last[last] = []\n",
        "        by_last[last].append(cds)\n",
        "    return exact_set, by_last\n",
        "\n",
        "def fuzzy_match(member_norm, by_last):\n",
        "    \"\"\"\n",
        "    Very simple fuzzy step:\n",
        "      - Compare only against candidates with the SAME LAST NAME\n",
        "      - Use best of difflib ratios\n",
        "      - Accept only if score >= FUZZY_SCORE_THRESHOLD\n",
        "    \"\"\"\n",
        "    #Skip if no matched last name exsits\n",
        "    if member_norm == \"\":\n",
        "        return None, 0\n",
        "    fir, las = first_last(member_norm)\n",
        "    if las not in by_last:\n",
        "        return None, 0\n",
        "\n",
        "    best = None\n",
        "    best_score = 0\n",
        "    for cand in by_last[las]:\n",
        "        score = best_similarity(member_norm, cand[\"name_norm\"])\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best = cand\n",
        "\n",
        "    if best is not None and best_score >= FUZZY_SCORE_THRESHOLD:\n",
        "        return best, best_score\n",
        "    return None, 0\n",
        "\n",
        "#main function\n",
        "\n",
        "def main():\n",
        "\n",
        "    data_dir = \"data\"\n",
        "    primary_file = \"congress_members_with_parties.csv\"\n",
        "    output_file = \"results_name_matching.csv\"\n",
        "\n",
        "    # Usage: python name_matcher.py [data_dir] [primary_file] [output_file]\n",
        "    if len(sys.argv) >= 2:\n",
        "        data_dir = sys.argv[1]\n",
        "    if len(sys.argv) >= 3:\n",
        "        primary_file = sys.argv[2]\n",
        "    if len(sys.argv) >= 4:\n",
        "        output_file = sys.argv[3]\n",
        "\n",
        "    primary_path = os.path.join(data_dir, primary_file)\n",
        "\n",
        "    # Read data\n",
        "    members = read_primary(primary_path)\n",
        "    candidates = read_elections(data_dir)\n",
        "    exact_set, by_last = build_indexes(candidates)\n",
        "\n",
        "    # Match\n",
        "    rows = []\n",
        "    for _, row in members.iterrows():\n",
        "        raw = detect_name_from_row(row)\n",
        "        raw = raw if raw != \"\" else safe_str(row.get(\"name\", \"\"))\n",
        "        norm = normalize_name(raw)\n",
        "        disp = \" \".join([t.capitalize() for t in norm.split()]) if norm != \"\" else raw\n",
        "        party = safe_str(row.get(\"party\", \"\"))\n",
        "\n",
        "        match_type = \"none\"\n",
        "        confidence = 0\n",
        "        m_raw = \"\"\n",
        "        m_norm = \"\"\n",
        "        m_disp = \"\"\n",
        "        m_year = \"\"\n",
        "        m_file = \"\"\n",
        "        notes = \"\"\n",
        "\n",
        "        # Exact first\n",
        "        if norm != \"\" and norm in exact_set:\n",
        "            # Find one matching candidate for year/file info\n",
        "            _, las = first_last(norm)\n",
        "            bucket = by_last.get(las, [])\n",
        "            found = None\n",
        "            for cand in bucket:\n",
        "                if cand[\"name_norm\"] == norm:\n",
        "                    found = cand\n",
        "                    break\n",
        "            if found is None:\n",
        "                for cand in candidates:\n",
        "                    if cand[\"name_norm\"] == norm:\n",
        "                        found = cand\n",
        "                        break\n",
        "            if found is not None:\n",
        "                match_type = \"exact\"\n",
        "                confidence = 100\n",
        "                m_raw = found[\"name_raw\"]\n",
        "                m_norm = found[\"name_norm\"]\n",
        "                m_disp = \" \".join([t.capitalize() for t in m_norm.split()])\n",
        "                m_year = found[\"year\"]\n",
        "                m_file = found[\"file\"]\n",
        "        else:\n",
        "            # Simple fuzzy\n",
        "            best, score = fuzzy_match(norm, by_last)\n",
        "            if best is not None:\n",
        "                match_type = \"fuzzy\"\n",
        "                confidence = int(score)\n",
        "                m_raw = best[\"name_raw\"]\n",
        "                m_norm = best[\"name_norm\"]\n",
        "                m_disp = \" \".join([t.capitalize() for t in m_norm.split()])\n",
        "                m_year = best[\"year\"]\n",
        "                m_file = best[\"file\"]\n",
        "            else:\n",
        "                notes = \"No high-confidence match\"\n",
        "\n",
        "        rows.append({\n",
        "            \"member_name_original\": raw,\n",
        "            \"member_name_normalized\": norm,\n",
        "            \"member_name_display\": disp,\n",
        "            \"party\": party,\n",
        "            \"matched\": \"yes\" if match_type in (\"exact\", \"fuzzy\") else \"no\",\n",
        "            \"match_type\": match_type,\n",
        "            \"confidence\": int(confidence),\n",
        "            \"matched_candidate_name_original\": m_raw,\n",
        "            \"matched_candidate_name_normalized\": m_norm,\n",
        "            \"matched_candidate_name_display\": m_disp,\n",
        "            \"election_year\": safe_str(m_year),\n",
        "            \"election_file\": safe_str(m_file),\n",
        "            \"notes\": notes\n",
        "        })\n",
        "\n",
        "#final output\n",
        "    out = pnd.DataFrame(rows).fillna(\"\")\n",
        "    order = {\"exact\": 0, \"fuzzy\": 1, \"none\": 2}\n",
        "    out[\"rank\"] = out[\"match_type\"].map(lambda x: order.get(x, 3))\n",
        "    out.sort_values(by=[\"rank\", \"confidence\", \"member_name_display\"], ascending=[True, False, True], inplace=True)\n",
        "    out.drop(columns=[\"rank\"], inplace=True)\n",
        "    out.to_csv(output_file, index=False)\n",
        "\n",
        "#summary output for quick overview of task\n",
        "    total = out.shape[0]\n",
        "    matched = int((out[\"matched\"] == \"yes\").sum())\n",
        "    exact = int((out[\"match_type\"] == \"exact\").sum())\n",
        "    fuzzy = int((out[\"match_type\"] == \"fuzzy\").sum())\n",
        "    print(\"Done.\")\n",
        "    print(\"Total members processed:\", total)\n",
        "    print(\"Matched:\", matched, \"(Exact:\", exact, \", Fuzzy:\", fuzzy, \")\")\n",
        "    print(\"Unmatched:\", total - matched)\n",
        "    print(\"Output file:\", output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmT3qrONwc0F",
        "outputId": "e9f93bce-4c45-487b-e507-3c389f3bd4d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting name_matcher.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#total output\n",
        "!python name_matcher.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tM0YF_v2Ojb",
        "outputId": "f65713b4-a651-4b7d-8b45-da4d667cf1fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Total members processed: 2873\n",
            "Matched: 1662 (Exact: 1098 , Fuzzy: 564 )\n",
            "Unmatched: 1211\n",
            "Output file: results_name_matching.csv\n"
          ]
        }
      ]
    }
  ]
}